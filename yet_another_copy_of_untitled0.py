# -*- coding: utf-8 -*-
"""Yet another copy of Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pcdJ0L8Krx4dtj6mMXkkEXDRMP-EncUn
"""

# 1. Install dependencies
!pip install streamlit faiss-cpu sentence-transformers langchain-community pyngrok pypdf groq langchain-groq

!pip install streamlit \
langchain==0.1.16 langchain-core==0.3.48 langchain-community==0.3.23 \
langsmith==0.1.125 langchain-groq==0.3.2 \
faiss-cpu sentence-transformers PyPDF2 pillow \
httpx==0.27.0 openai==1.17.0 \
deep-translator

!pip install SpeechRecognition

!pip install deep-translator

import os
os.environ["GROQ_API_KEY"] = "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"

from google.colab import drive
drive.mount('/content/drive')

import os
import streamlit as st
import speech_recognition as sr
from deep_translator import GoogleTranslator
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain_groq import ChatGroq
from PIL import Image
from io import BytesIO
import base64

# ============ CONFIG ============
os.environ["GROQ_API_KEY"] = "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"
MODEL_NAME = "llama3-8b-8192"
PDF_PATHS = {
    "Pharmacology": "/content/drive/MyDrive/Lippincott Illustrated Reviews Pharmacology Seventh Edition.pdf",
    "Pain management": "/content/drive/MyDrive/pain_wise_a_patients_guide_to_pain_management_1nbsped_1578264081.pdf",
    "First aid": "/content/drive/MyDrive/New-Vital-First-Aid-First-Aid-Book-112019.pdf"
}
# ================================


def load_medical_docs(path):
    loader = PyPDFLoader(path)
    docs = loader.load()
    print(f"{len(docs)}")
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_documents(docs)

def embed_documents(docs):
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    return FAISS.from_documents(docs, embeddings)

def build_qa_system(faiss_index):
    llm = ChatGroq(api_key=os.getenv("GROQ_API_KEY"), model_name=MODEL_NAME)
    return RetrievalQA.from_chain_type(llm=llm, retriever=faiss_index.as_retriever(search_type="similarity", k=4))

def recognize_speech():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("Listening... Speak now.")
        audio = recognizer.listen(source, phrase_time_limit=5)
        try:
            return recognizer.recognize_google(audio)
        except sr.UnknownValueError:
            st.warning("Sorry, could not understand the audio.")
        except sr.RequestError:
            st.error("Speech recognition service is unavailable.")
    return ""

def translate_to_arabic(text):
    try:
        # الترجمة من اللغة الأصلية إلى اللغة العربية
        return GoogleTranslator(source='auto', target='ar').translate(text)
    except Exception as e:
        return "تعذر الترجمة حالياً."

def generate_image_from_text(text):
    # This is a placeholder. Replace with real image generation if needed.
    img = Image.new('RGB', (300, 100), color=(73, 109, 137))
    return img

# Streamlit App
def main():
    st.set_page_config(page_title="Medical Chatbot (LLaMA 3 + RAG)", layout="centered")
    st.title("Medical Question Answering Chatbot (RAG + LLaMA 3)")

    if "qa_chain" not in st.session_state:
        st.session_state.qa_chain = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "selected_book" not in st.session_state:
        st.session_state.selected_book = list(PDF_PATHS.keys())[0]

    # Book selection buttons
    st.subheader("Select Book:")
    for book_name in PDF_PATHS:
        if st.button(book_name):
            st.session_state.selected_book = book_name
            st.session_state.qa_chain = None
            st.session_state.chat_history = []

    # Load model for selected book
    if st.session_state.qa_chain is None:
        with st.spinner(f"Loading {st.session_state.selected_book}..."):
            docs = load_medical_docs(PDF_PATHS[st.session_state.selected_book])
            faiss_index = embed_documents(docs)
            st.session_state.qa_chain = build_qa_system(faiss_index)

    # Input options
    col1, col2 = st.columns([3, 1])
    with col1:
        query = st.text_input("Ask a medical question:")
    with col2:
        if st.button("Use Voice"):
            voice_input = recognize_speech()
            if voice_input:
                st.success(f"You said: {voice_input}")
                query = voice_input

    # Answering
    if query:
        with st.spinner("Generating answer..."):
            result = st.session_state.qa_chain.run(query)
            translation = translate_to_arabic(result)
            st.session_state.chat_history.append({
                "question": query,
                "answer": result,
                "translated": translation
            })

    # Chat History
    st.markdown("---")
    st.subheader("Chat History")
    for chat in reversed(st.session_state.chat_history):
        st.markdown(f"**You:** {chat['question']}")
        st.markdown(f"**Bot:** {chat['answer']}")
        st.markdown(f"**ترجمة:** {chat['translated']}")

        if "image" in chat['answer'].lower() or "diagram" in chat['answer'].lower():
            if st.button(f"Generate Image for: {chat['question']}"):
                img = generate_image_from_text(chat['answer'])
                st.image(img, caption="Generated Illustration")

if __name__ == "__main__":
    main()

from pyngrok import ngrok
!ngrok config add-authtoken 2w9WWgvNAVvctBnPUecvER45uQ0_2KgsjJkoPHM939isd4hrZ
public_url = ngrok.connect(8501)
print(f"Streamlit app is live at: {public_url}")

!streamlit run medical_rag_chatbot.py &/content/Logs.txt &